---
title: Portfolio 1 IA 
date: 2023-10-14 17:23:00 -0400
categories: [studies,ai,porfolio1]
tags: [ia,studies]
---

# **Intruduction**
What is intelligence, and what is artificial intelligence? These are profound questions that we will explore from a particular perspective.

To embark on this journey, it's crucial to first establish a foundation by delving into the historical context of intelligence, understanding its implications in various fields, including art, and dissecting both the advantages and potential risks associated with artificial intelligence. However, before we dive into these complex realms, we must grasp the fundamental definitions.

According to the dictionary, intelligence is the capacity for learning, comprehending, and effectively dealing with new and challenging situations. It encompasses the use of reason, application of knowledge, and the ability to comprehend the world around us.

On the other hand, the term 'artificial' is simpler to defineâ€”it refers to something created by humans. However, the dictionary does not provide an explicit definition of 'Artificial Intelligence,' which leads us to contemplate its essence.

Building upon the interpretations of prominent figures like IBM and pioneers in the field such as Russell and Norvig, Artificial Intelligence can be summarized as a machine capable of mimicking human behaviors and cognitive processes. It is this definition that forms the basis of our exploration into the intriguing world of intelligence and artificial intelligence.

# **Discussion**

In this section, we delve deeper into the world of Artificial Intelligence, exploring key concepts, the Turing Test, contemporary AI models, and the prevailing standard model.

## **The Turing Test**
The Turing Test, a pivotal concept in AI, can be divided into several components:

* Processing Natural Language: The ability to communicate with humans effectively.
* Representation of Knowledge: Storing and managing acquired knowledge.
* Automated Reasoning: Capable of answering questions and drawing new conclusions.
* Machine Learning: Adapting to new situations and identifying patterns.
* Computer Vision and Speech Recognition: Understanding the world.
* Robotics: Manipulating objects and mobility.

This test goes beyond solving problems correctly; it assesses the sequence and timing of reasoning steps in comparison to human problem-solving.

## **Modern Applications of AI**
Beyond definitions and testing, let's explore how AI is utilized in contemporary scenarios.

## **Acting Rationally**
The rational agent concept is fundamental. An AI system should:

* Operate autonomously.
* Perceive its environment.
* Persist over an extended duration.
* Adapt to changes.
* Establish and pursue goals.

 Rationality standards are mathematically well-defined and universal, serving as a foundation for agent designs proven to achieve their objectives.

## **The Standard Model**
* Historically, the rational agent approach has been the cornerstone of AI.
* AI emphasizes creating agents that make the "right" decisions based on provided objectives.
* The definition of the "right thing" depends on the objective set for the agent.
* This approach is so prevalent that it's often termed the standard model.

## **Challenges with the Standard Model**
While the standard model has guided AI research effectively, it may not be suitable in the long run.
It assumes we can fully and accurately specify the machine's objective.

In practical, real-world scenarios, defining objectives becomes increasingly challenging, as seen in autonomous cars.

The misalignment between our true preferences and machine-programmed goals is known as the value alignment problem, leading to adverse consequences when objectives are wrongly specified.

## **Observations on this Introduction**
Adaptations to the standard model are essential, considering the computational tractability of the problem and the necessity for machines to pursue objectives beneficial to humanity, even when objectives are uncertain.

Artificial Intelligence draws from various fields, including philosophy, mathematics, economics, neuroscience, psychology, computer engineering, control, cybernetics, and linguistics, among others, making it a multidisciplinary endeavor.

# **History**

In this section, we'll explore the historical development of Artificial Intelligence (AI) from its early conceptualizations to its resurgence in modern times.

## **Early Notions of AI**

In the year 1863, English author Samuel Butler, also known as Cellarius, authored "Darwin among the Machines," which was published in the newspaper The Press. This article, one of the earliest discussions of AI, predated the formal definition of AI. It posited the idea that machines could exhibit a form of mechanistic life, akin to Darwinian natural selection, suggesting an evolutionary path where machines could eventually surpass humans in dominance.

## **The First AI Encounters**

Defining the first AI is a challenge, but early examples include the mythological creature Talos from Mitology and Ficcion, dating back to 400 A.C. Talos was a giant copper-made robot designed to act as a guardian of Crete.

## **The Emergence of AI (1943 - 1956)**

The foundations of AI were laid by Warren McCulloch and Walter Pitts through a neuron model, where neurons could be in an "on" or "off" state based on stimulation from neighboring neurons. This marked a significant precursor in the AI field.

Alan Turing made influential contributions in this period, introducing concepts like the Turing test, machine learning, genetic algorithms, and reinforcement learning. Turing's insight suggested that developing learning algorithms and teaching machines would be more efficient than manually programming their intelligence.

In 1956, AI gained further recognition with significant events.


![The Fathers of AI](imgs/Portfolio_img_1.jpeg)


## **Great Expectations for AI**

The era of AI development saw notable experiments, such as Herbert Gelernter's Geometry Theorem Prover, which could prove complex theorems, and Arthur Samuel's work in reinforcement learning for playing checkers.

However, a realization emerged: machines could only learn what they could represent, and their representational capabilities were limited. As a response, specialized systems emerged, preparing the AI's domain knowledge, enabling them to tackle problems more effectively. This gave rise to high expectations for AI, leading to significant investments and technological advancements.

## **The Winter**

Despite these great expectations, the AI industry faced a downturn in 1986. Projects and companies struggled to deliver on their promises within short timelines, casting doubt on the feasibility of AI. Challenges included building and maintaining expert systems for complex domains, especially when faced with uncertainty and the inability to learn from experience.

## **The Return of AI (1987)**

In the late 1980s, the AI field experienced a resurgence. Multiple groups rediscovered the backpropagation learning algorithm initially developed in the 1960s. Connectionist models that formed internal concepts more aligned with the real world began to emerge. These models were adaptable and could learn from examples, showing promise for future applications.

Rich Sutton introduced reinforcement learning concepts in 1988, used in areas like Markov decision processes. This period marked the gradual convergence of AI subfields, including computer vision, robotics, speech recognition, multi-agent systems, and natural language processing.

## **The Era of Big Data**

Advancements in computing power and the birth of the World Wide Web enabled the creation of massive datasets, often referred to as "big data." These datasets encompass vast amounts of text, images, speech, video, genomic data, and more. Learning algorithms specifically designed for big data emerged during this period.

## **The Rise of Deep Learning**

Deep learning, a machine learning approach involving multiple layers of simple, tunable computing elements, had been used since the 1970s but gained prominence in 2011. It revolutionized speech recognition and object recognition. The 2012 ImageNet competition, where a deep learning system excelled, marked a significant milestone. Deep learning achieved breakthroughs in speech recognition, machine translation, medical diagnostics, and game-playing, such as AlphaGo's victory over a human world champion in 2016.

These achievements rekindled interest in AI across various sectors, including education, business, investment, government, media, and the public.

## **Summing It Up**

- In the 1960s, AI focused on inference by search, but the lack of sufficient material for AI led to a "winter."
- In 1987, AI shifted toward inference by knowledge, expanding the scope but also increasing complexity, resulting in the second "winter."
- Between 1998 and 2012, AI made significant progress in reasoning by learning, particularly in deep learning, which remains a foundational aspect of AI today.

## **Neats vs. Scruffies**

A distinction emerged between "Neats" and "Scruffies." Neats advocated grounding AI theories in mathematical rigor, while Scruffies preferred experimenting with various ideas and evaluating their practicality. In the 1990s and 21st century, AI research predominantly adopted Neat approaches, but the recent emphasis on deep learning signifies a resurgence of Scruffies' influence.

# **AI nowdays**
